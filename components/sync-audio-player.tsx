"use client"

import { useState, useRef, useEffect, useCallback, useMemo } from "react"
import { Button } from "@/components/ui/button"
import { Card, CardContent } from "@/components/ui/card"
import { Play, Pause, SkipBack, SkipForward, Download } from "lucide-react"

interface SentenceTimestamp {
  text: string
  start: number
  end?: number
}

interface SyncAudioPlayerProps {
  audioUrl: string
  text: string
  sentenceTimestamps?: SentenceTimestamp[]
  onDownload?: () => void
}

export default function SyncAudioPlayer({ audioUrl, text, sentenceTimestamps = [], onDownload }: SyncAudioPlayerProps) {
  const audioRef = useRef<HTMLAudioElement>(null)
  const [isPlaying, setIsPlaying] = useState(false)
  const [currentTime, setCurrentTime] = useState(0)
  const [duration, setDuration] = useState(0)
  const [processedTimestamps, setProcessedTimestamps] = useState<SentenceTimestamp[]>([])
  const [currentSentenceIndex, setCurrentSentenceIndex] = useState(-1)
  const [isAudioLoaded, setIsAudioLoaded] = useState(false)
  const [audioLoadError, setAudioLoadError] = useState<string | null>(null)
  const [audioLoadingState, setAudioLoadingState] = useState<'idle' | 'loading' | 'loaded' | 'error'>('idle')
  const [audioMetadataLoaded, setAudioMetadataLoaded] = useState(false)
  
  // æ·»åŠ é˜²æŠ–å’Œæ€§èƒ½ä¼˜åŒ–çš„refs
  const lastUpdateTime = useRef<number>(0)
  const timeUpdateThrottle = useRef<number | null>(null)
  const lastSentenceIndex = useRef<number>(-1)

  // è·å–å½“å‰å¥å­ç´¢å¼•ï¼Œä½¿ç”¨æ”¹è¿›çš„å‡½æ•°
  const getCurrentSentenceIndex = useCallback(
    (currentTime: number): number => {
      if (processedTimestamps.length === 0) {
        return -1
      }

      // éªŒè¯è¾“å…¥å‚æ•°
      if (typeof currentTime !== "number" || isNaN(currentTime) || currentTime < 0) {
        return -1
      }

      // ä½¿ç”¨æ”¹è¿›çš„ç®—æ³•ï¼ŒåŒ…å«å®¹å·®æœºåˆ¶
      const tolerance = 0.15 // 150mså®¹å·®ï¼Œé€‚åº”éŸ³é¢‘æ’­æ”¾çš„å¾®å°å»¶è¿Ÿ

      // é¦–å…ˆè¿›è¡Œç²¾ç¡®åŒ¹é…
      for (let i = 0; i < processedTimestamps.length; i++) {
        const sentence = processedTimestamps[i]
        const startTime = sentence.start
        const endTime = sentence.end || (i < processedTimestamps.length - 1 ? processedTimestamps[i + 1].start : Infinity)
        
        // ç²¾ç¡®åŒ¹é…ï¼šå½“å‰æ—¶é—´åœ¨å¥å­çš„å¼€å§‹å’Œç»“æŸæ—¶é—´ä¹‹é—´
        if (currentTime >= startTime && currentTime < endTime) {
          return i
        }
      }

      // å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•å®¹å·®åŒ¹é…
      for (let i = 0; i < processedTimestamps.length; i++) {
        const sentence = processedTimestamps[i]
        const startTime = sentence.start
        const endTime = sentence.end || (i < processedTimestamps.length - 1 ? processedTimestamps[i + 1].start : Infinity)
        
        // å®¹å·®åŒ¹é…ï¼šå…è®¸ä¸€å®šçš„æ—¶é—´åå·®
        if (currentTime >= startTime - tolerance && currentTime < endTime + tolerance) {
          return i
        }
      }

      // è¾¹ç•Œæƒ…å†µå¤„ç†
      const firstSentence = processedTimestamps[0]
      const lastSentence = processedTimestamps[processedTimestamps.length - 1]

      // å¦‚æœå½“å‰æ—¶é—´åœ¨ç¬¬ä¸€ä¸ªå¥å­ä¹‹å‰ï¼ˆä½†åœ¨å®¹å·®èŒƒå›´å†…ï¼‰ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¥å­
      if (currentTime < firstSentence.start && currentTime >= firstSentence.start - tolerance) {
        return 0
      }

      // å¦‚æœå½“å‰æ—¶é—´åœ¨æœ€åä¸€ä¸ªå¥å­ä¹‹åï¼Œè¿”å›æœ€åä¸€ä¸ªå¥å­
      if (currentTime >= lastSentence.start) {
        return processedTimestamps.length - 1
      }

      // ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåªæœ‰ä¸€ä¸ªå¥å­ä¸”æ—¶é—´åœ¨åˆç†èŒƒå›´å†…ï¼Œå§‹ç»ˆé«˜äº®è¯¥å¥å­
      if (processedTimestamps.length === 1 && currentTime >= 0) {
        return 0
      }

      return -1
    },
    [processedTimestamps],
  )

  // ä¼˜åŒ–çš„æ—¶é—´æ›´æ–°å‡½æ•°ï¼Œä½¿ç”¨èŠ‚æµæœºåˆ¶
  const throttledTimeUpdate = useCallback((newTime: number) => {
    const now = Date.now()
    const UPDATE_INTERVAL = 100 // 100msæ›´æ–°é—´éš”ï¼Œé™ä½CPUä½¿ç”¨ç‡

    // æ¸…é™¤ä¹‹å‰çš„å®šæ—¶å™¨
    if (timeUpdateThrottle.current) {
      clearTimeout(timeUpdateThrottle.current)
    }

    // å¦‚æœè·ç¦»ä¸Šæ¬¡æ›´æ–°æ—¶é—´å¤ªçŸ­ï¼Œä½¿ç”¨å®šæ—¶å™¨å»¶è¿Ÿæ›´æ–°
    if (now - lastUpdateTime.current < UPDATE_INTERVAL) {
      timeUpdateThrottle.current = window.setTimeout(() => {
        setCurrentTime(newTime)
        lastUpdateTime.current = Date.now()
        
        // åªæœ‰åœ¨å¥å­ç´¢å¼•å‘ç”Ÿå˜åŒ–æ—¶æ‰æ›´æ–°
        const newSentenceIndex = getCurrentSentenceIndex(newTime)
        if (newSentenceIndex !== lastSentenceIndex.current) {
          setCurrentSentenceIndex(newSentenceIndex)
          lastSentenceIndex.current = newSentenceIndex
        }
      }, UPDATE_INTERVAL - (now - lastUpdateTime.current))
    } else {
      // ç«‹å³æ›´æ–°
      setCurrentTime(newTime)
      lastUpdateTime.current = now
      
      // åªæœ‰åœ¨å¥å­ç´¢å¼•å‘ç”Ÿå˜åŒ–æ—¶æ‰æ›´æ–°
      const newSentenceIndex = getCurrentSentenceIndex(newTime)
      if (newSentenceIndex !== lastSentenceIndex.current) {
        setCurrentSentenceIndex(newSentenceIndex)
        lastSentenceIndex.current = newSentenceIndex
      }
    }
  }, [getCurrentSentenceIndex])

  // æ¸…ç†å‡½æ•°
  useEffect(() => {
    return () => {
      if (timeUpdateThrottle.current) {
        clearTimeout(timeUpdateThrottle.current)
      }
    }
  }, [])

  // éŸ³é¢‘URLå˜åŒ–æ—¶é‡ç½®çŠ¶æ€
  useEffect(() => {
    if (audioUrl) {
      setAudioLoadingState('loading')
      setAudioLoadError(null)
      setIsAudioLoaded(false)
      setAudioMetadataLoaded(false)
      setCurrentTime(0)
      setCurrentSentenceIndex(-1)
      setIsPlaying(false)
      console.log("Audio URL changed, resetting states:", audioUrl)
    }
  }, [audioUrl])

  // è°ƒè¯•ä¿¡æ¯
  useEffect(() => {
    console.log("Received sentenceTimestamps:", sentenceTimestamps)
  }, [sentenceTimestamps])

  // å¤„ç†æ—¶é—´æˆ³ï¼Œä½¿ç”¨æ”¹è¿›çš„éªŒè¯å’Œå¤„ç†é€»è¾‘
  useEffect(() => {
    if (sentenceTimestamps.length > 0) {
      console.log("Processing timestamps:", sentenceTimestamps)

      // ä½¿ç”¨ç»Ÿä¸€çš„æ—¶é—´æˆ³å¤„ç†å‡½æ•°
      import("@/utils/text-processor").then(({ processTimestamps }) => {
        const processed = processTimestamps(sentenceTimestamps, duration || undefined)
        console.log("Processed timestamps:", processed)
        setProcessedTimestamps(processed)
      })
    } else if (text && isAudioLoaded) {
      // å¦‚æœæ²¡æœ‰æä¾›æ—¶é—´æˆ³ï¼Œåˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
      console.log("No timestamps provided, using fallback method")
      import("@/utils/text-processor").then(({ splitIntoSentences, estimateTimestamps }) => {
        const sentences = splitIntoSentences(text)
        const estimatedTimestamps = estimateTimestamps(sentences, duration || text.length * 0.1)
        console.log("Estimated timestamps:", estimatedTimestamps)
        setProcessedTimestamps(estimatedTimestamps)
      })
    }
  }, [sentenceTimestamps, text, duration, isAudioLoaded])

  // éŸ³é¢‘åŠ è½½å®Œæˆåæ›´æ–°å®é™…æ—¶é•¿å’Œæ—¶é—´æˆ³ï¼Œå¢å¼ºçŠ¶æ€ç®¡ç†
  useEffect(() => {
    const audio = audioRef.current
    if (!audio) return

    const handleLoadStart = () => {
      console.log("Audio load started")
      setAudioLoadingState('loading')
      setAudioLoadError(null)
    }

    const handleLoadedMetadata = () => {
      try {
        const actualDuration = audio.duration
        console.log("Audio metadata loaded, duration:", actualDuration)
        
        if (isNaN(actualDuration) || actualDuration <= 0) {
          console.warn("Invalid audio duration:", actualDuration)
          setAudioLoadError("éŸ³é¢‘æ—¶é•¿æ— æ•ˆ")
          setAudioLoadingState('error')
          return
        }

        setDuration(actualDuration)
        setAudioMetadataLoaded(true)
        setAudioLoadingState('loaded')

        // åŠ¨æ€æ ¡å‡†æ—¶é—´æˆ³ - ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿
        if (processedTimestamps.length > 0) {
          import("@/utils/text-processor").then(({ estimateTimestamps, splitIntoSentences }) => {
            
            // æ£€æŸ¥ä¼°ç®—æ—¶é•¿ä¸å®é™…æ—¶é•¿çš„å·®å¼‚
            const estimatedDuration = processedTimestamps.length > 0 ? 
              Math.max(...processedTimestamps.map(ts => ts.end || ts.start)) : 0
            
            const durationDiff = Math.abs(actualDuration - estimatedDuration)
            const diffPercentage = estimatedDuration > 0 ? durationDiff / estimatedDuration : 1
            
            console.log(`Duration comparison: estimated=${estimatedDuration}s, actual=${actualDuration}s, diff=${diffPercentage.toFixed(2)}`)
            
            // å¦‚æœå·®å¼‚è¶…è¿‡20%ï¼Œé‡æ–°è®¡ç®—æ—¶é—´æˆ³
            if (diffPercentage > 0.2) {
              console.log("ğŸ”„ Recalibrating timestamps due to significant duration difference")
              const sentences = processedTimestamps.map(ts => ts.text)
              const recalibratedTimestamps = estimateTimestamps(sentences, actualDuration)
              console.log("Recalibrated timestamps:", recalibratedTimestamps)
              setProcessedTimestamps(recalibratedTimestamps)
            } else {
              // å°å¹…è°ƒæ•´ï¼šæŒ‰æ¯”ä¾‹ç¼©æ”¾ç°æœ‰æ—¶é—´æˆ³
              console.log("ğŸ”§ Fine-tuning timestamps with scaling")
              const scaleFactor = actualDuration / estimatedDuration
              const scaledTimestamps = processedTimestamps.map(ts => ({
                ...ts,
                start: ts.start * scaleFactor,
                end: ts.end ? ts.end * scaleFactor : actualDuration,
              }))
              
              // ç¡®ä¿æœ€åä¸€ä¸ªå¥å­ç»“æŸäºå®é™…æ—¶é•¿
              if (scaledTimestamps.length > 0) {
                scaledTimestamps[scaledTimestamps.length - 1].end = actualDuration
              }
              
              console.log("Scaled timestamps:", scaledTimestamps)
              setProcessedTimestamps(scaledTimestamps)
            }
          })
        }
      } catch (error) {
        console.error("Error in handleLoadedMetadata:", error)
        setAudioLoadError("éŸ³é¢‘å…ƒæ•°æ®åŠ è½½å¤±è´¥")
        setAudioLoadingState('error')
      }
    }

    const handleCanPlay = () => {
      console.log("Audio can play")
      setIsAudioLoaded(true)
    }

    const handleLoadError = (event: Event) => {
      console.error("Audio load error:", event)
      setAudioLoadError("éŸ³é¢‘åŠ è½½å¤±è´¥")
      setAudioLoadingState('error')
      setIsAudioLoaded(false)
    }

    const handleStalled = () => {
      console.warn("Audio loading stalled")
      // ä¸æ”¹å˜çŠ¶æ€ï¼Œåªè®°å½•è­¦å‘Š
    }

    const handleProgress = () => {
      if (audio.buffered.length > 0) {
        const bufferedEnd = audio.buffered.end(audio.buffered.length - 1)
        const duration = audio.duration
        if (duration > 0) {
          const bufferedPercent = (bufferedEnd / duration) * 100
          console.log(`Audio buffered: ${bufferedPercent.toFixed(1)}%`)
        }
      }
    }

    audio.addEventListener("loadstart", handleLoadStart)
    audio.addEventListener("loadedmetadata", handleLoadedMetadata)
    audio.addEventListener("canplay", handleCanPlay)
    audio.addEventListener("error", handleLoadError)
    audio.addEventListener("stalled", handleStalled)
    audio.addEventListener("progress", handleProgress)

    return () => {
      try {
        audio.removeEventListener("loadstart", handleLoadStart)
        audio.removeEventListener("loadedmetadata", handleLoadedMetadata)
        audio.removeEventListener("canplay", handleCanPlay)
        audio.removeEventListener("error", handleLoadError)
        audio.removeEventListener("stalled", handleStalled)
        audio.removeEventListener("progress", handleProgress)
      } catch (error) {
        console.error("Error removing audio load event listeners:", error)
      }
    }
  }, [text, sentenceTimestamps]) // ç§»é™¤processedTimestampsä¾èµ–ä»¥é¿å…å¾ªç¯

  // ç›‘å¬æ’­æ”¾è¿›åº¦ï¼Œå¢å¼ºé”™è¯¯å¤„ç†
  useEffect(() => {
    const audio = audioRef.current
    if (!audio) {
      console.warn("Audio element not found, skipping event listeners setup")
      return
    }

    const handleTimeUpdate = () => {
      try {
        if (audio.currentTime !== undefined && !isNaN(audio.currentTime)) {
          // ä½¿ç”¨èŠ‚æµçš„æ—¶é—´æ›´æ–°å‡½æ•°
          throttledTimeUpdate(audio.currentTime)
        } else {
          console.warn("Invalid audio currentTime:", audio.currentTime)
        }
      } catch (error) {
        console.error("Error in handleTimeUpdate:", error)
      }
    }

    const handlePlay = () => {
      try {
        setIsPlaying(true)
      } catch (error) {
        console.error("Error in handlePlay:", error)
      }
    }

    const handlePause = () => {
      try {
        setIsPlaying(false)
      } catch (error) {
        console.error("Error in handlePause:", error)
      }
    }

    const handleEnded = () => {
      try {
        setIsPlaying(false)
        setCurrentSentenceIndex(-1) // é‡ç½®å½“å‰å¥å­ç´¢å¼•
      } catch (error) {
        console.error("Error in handleEnded:", error)
      }
    }

    const handleError = (event: Event) => {
      console.error("Audio playback error:", event)
      setIsPlaying(false)
    }

    audio.addEventListener("timeupdate", handleTimeUpdate)
    audio.addEventListener("play", handlePlay)
    audio.addEventListener("pause", handlePause)
    audio.addEventListener("ended", handleEnded)
    audio.addEventListener("error", handleError)

    return () => {
      try {
        audio.removeEventListener("timeupdate", handleTimeUpdate)
        audio.removeEventListener("play", handlePlay)
        audio.removeEventListener("pause", handlePause)
        audio.removeEventListener("ended", handleEnded)
        audio.removeEventListener("error", handleError)
      } catch (error) {
        console.error("Error removing audio event listeners:", error)
      }
    }
  }, [throttledTimeUpdate]) // ä½¿ç”¨throttledTimeUpdateè€Œä¸æ˜¯getCurrentSentenceIndex

  // æ’­æ”¾/æš‚åœæ§åˆ¶ï¼Œè€ƒè™‘éŸ³é¢‘åŠ è½½çŠ¶æ€
  const togglePlayPause = () => {
    const audio = audioRef.current
    if (!audio) {
      console.error("Audio element not available for play/pause control")
      return
    }

    // æ£€æŸ¥éŸ³é¢‘åŠ è½½çŠ¶æ€
    if (audioLoadingState === 'loading') {
      console.warn("Audio is still loading, cannot play yet")
      return
    }

    if (audioLoadingState === 'error') {
      console.error("Audio has load error, cannot play")
      return
    }

    if (!isAudioLoaded) {
      console.warn("Audio is not ready for playback")
      return
    }

    try {
      if (isPlaying) {
        audio.pause()
      } else {
        // ç¡®ä¿éŸ³é¢‘å…ƒæ•°æ®å·²åŠ è½½
        if (!audioMetadataLoaded) {
          console.warn("Audio metadata not loaded, waiting...")
          audio.load() // é‡æ–°åŠ è½½éŸ³é¢‘
          return
        }

        audio.play().catch((error) => {
          console.error("Audio play failed:", error)
          setIsPlaying(false) // ç¡®ä¿çŠ¶æ€åŒæ­¥
          
          // å°è¯•é‡æ–°åŠ è½½éŸ³é¢‘
          if (error.name === 'NotAllowedError') {
            console.log("Playback was prevented by browser policy")
          } else {
            console.log("Attempting to reload audio...")
            audio.load()
          }
        })
      }
    } catch (error) {
      console.error("Error in togglePlayPause:", error)
      setIsPlaying(false)
    }
  }

  // è·³è½¬åˆ°ä¸Šä¸€å¥ï¼Œå¢å¼ºé”™è¯¯å¤„ç†
  const skipToPreviousSentence = () => {
    try {
      if (currentSentenceIndex <= 0 || processedTimestamps.length === 0) {
        console.warn("Cannot skip to previous sentence: at beginning or no timestamps available")
        return
      }

      const newIndex = Math.max(0, currentSentenceIndex - 1)
      jumpToSentence(newIndex)
    } catch (error) {
      console.error("Error in skipToPreviousSentence:", error)
    }
  }

  // è·³è½¬åˆ°ä¸‹ä¸€å¥ï¼Œå¢å¼ºé”™è¯¯å¤„ç†
  const skipToNextSentence = () => {
    try {
      if (currentSentenceIndex >= processedTimestamps.length - 1 || processedTimestamps.length === 0) {
        console.warn("Cannot skip to next sentence: at end or no timestamps available")
        return
      }

      const newIndex = Math.min(processedTimestamps.length - 1, currentSentenceIndex + 1)
      jumpToSentence(newIndex)
    } catch (error) {
      console.error("Error in skipToNextSentence:", error)
    }
  }

  // ç‚¹å‡»å¥å­è·³è½¬ï¼Œå¢å¼ºé”™è¯¯å¤„ç†
  const jumpToSentence = (index: number) => {
    try {
      // éªŒè¯è¾“å…¥å‚æ•°
      if (typeof index !== "number" || isNaN(index)) {
        console.error("Invalid sentence index:", index)
        return
      }

      if (index < 0 || index >= processedTimestamps.length) {
        console.warn(`Sentence index ${index} is out of range (0-${processedTimestamps.length - 1})`)
        return
      }

      const audio = audioRef.current
      if (!audio) {
        console.error("Audio element not available for sentence jumping")
        return
      }

      const sentence = processedTimestamps[index]
      if (!sentence) {
        console.error(`No sentence found at index ${index}`)
        return
      }

      const startTime = sentence.start
      console.log(`Jumping to sentence ${index} at time ${startTime}`)

      // éªŒè¯éŸ³é¢‘å…ƒç´ çŠ¶æ€
      if (isNaN(audio.duration) || audio.duration === 0) {
        console.warn("Audio duration not available, jumping anyway")
      }

      // ç¡®ä¿æ—¶é—´åœ¨æœ‰æ•ˆèŒƒå›´å†…
      if (typeof startTime === "number" && !isNaN(startTime) && startTime >= 0) {
        if (audio.duration && startTime <= audio.duration) {
          // è·³è½¬åˆ°å¥å­çš„å¼€å§‹æ—¶é—´
          audio.currentTime = startTime
        } else if (!audio.duration) {
          // å¦‚æœéŸ³é¢‘è¿˜åœ¨åŠ è½½ï¼Œç›´æ¥è®¾ç½®æ—¶é—´
          audio.currentTime = startTime
        } else {
          console.warn(`Start time ${startTime} exceeds audio duration ${audio.duration}, clamping to duration`)
          audio.currentTime = Math.min(startTime, audio.duration)
        }

        // å¦‚æœæ²¡æœ‰æ’­æ”¾ï¼Œåˆ™å¼€å§‹æ’­æ”¾
        if (!isPlaying) {
          audio.play().catch((error) => {
            console.error("Failed to start playback after sentence jump:", error)
            setIsPlaying(false)
          })
        }
      } else {
        console.error(`Invalid start time: ${startTime}, defaulting to beginning of audio`)
        // å¦‚æœæ—¶é—´æ— æ•ˆï¼Œé»˜è®¤è·³è½¬åˆ°éŸ³é¢‘å¼€å§‹
        audio.currentTime = 0

        // å¦‚æœæ²¡æœ‰æ’­æ”¾ï¼Œåˆ™å¼€å§‹æ’­æ”¾
        if (!isPlaying) {
          audio.play().catch((error) => {
            console.error("Failed to start playback after fallback jump:", error)
            setIsPlaying(false)
          })
        }
      }
    } catch (error) {
      console.error("Error in jumpToSentence:", error)
    }
  }

  // æ ¼å¼åŒ–æ—¶é—´ï¼Œå¢å¼ºé”™è¯¯å¤„ç†
  const formatTime = (time: number) => {
    try {
      // éªŒè¯è¾“å…¥
      if (typeof time !== "number" || isNaN(time) || time < 0) {
        return "0:00"
      }

      // å¤„ç†æ— ç©·å¤§çš„æƒ…å†µ
      if (!isFinite(time)) {
        return "0:00"
      }

      const minutes = Math.floor(time / 60)
      const seconds = Math.floor(time % 60)
      return `${minutes}:${seconds.toString().padStart(2, "0")}`
    } catch (error) {
      console.error("Error in formatTime:", error)
      return "0:00"
    }
  }

  return (
    <Card className="w-full">
      <CardContent className="p-4 space-y-4">
        {/* éšè—çš„éŸ³é¢‘å…ƒç´  */}
        <audio ref={audioRef} src={audioUrl} preload="metadata" />

        {/* æ’­æ”¾æ§åˆ¶å™¨ */}
        <div className="flex items-center justify-between">
          <div className="flex items-center space-x-2">
            <Button 
              variant="outline" 
              size="icon" 
              onClick={skipToPreviousSentence} 
              disabled={currentSentenceIndex <= 0 || audioLoadingState !== 'loaded' || !isAudioLoaded}
            >
              <SkipBack className="h-4 w-4" />
            </Button>

            <Button 
              variant="outline" 
              size="icon" 
              onClick={togglePlayPause}
              disabled={audioLoadingState === 'loading' || audioLoadingState === 'error' || !isAudioLoaded}
            >
              {audioLoadingState === 'loading' ? (
                <div className="h-4 w-4 animate-spin rounded-full border-2 border-primary border-t-transparent" />
              ) : isPlaying ? (
                <Pause className="h-4 w-4" />
              ) : (
                <Play className="h-4 w-4" />
              )}
            </Button>

            <Button
              variant="outline"
              size="icon"
              onClick={skipToNextSentence}
              disabled={currentSentenceIndex >= processedTimestamps.length - 1 || audioLoadingState !== 'loaded' || !isAudioLoaded}
            >
              <SkipForward className="h-4 w-4" />
            </Button>
          </div>

          <div className="text-sm text-muted-foreground">
            {formatTime(currentTime)} / {formatTime(duration)}
          </div>

          {onDownload && (
            <Button variant="outline" size="icon" onClick={onDownload}>
              <Download className="h-4 w-4" />
            </Button>
          )}
        </div>

        {/* é”™è¯¯çŠ¶æ€æ˜¾ç¤º */}
        {audioLoadError && (
          <div className="px-3 py-2 bg-destructive/10 border border-destructive/20 rounded-md">
            <p className="text-sm text-destructive">
              âš ï¸ {audioLoadError}
            </p>
          </div>
        )}

        {/* åŠ è½½çŠ¶æ€æ˜¾ç¤º */}
        {audioLoadingState === 'loading' && (
          <div className="px-3 py-2 bg-muted rounded-md">
            <p className="text-sm text-muted-foreground flex items-center gap-2">
              <div className="h-3 w-3 animate-spin rounded-full border-2 border-primary border-t-transparent" />
              æ­£åœ¨åŠ è½½éŸ³é¢‘...
            </p>
          </div>
        )}

        {/* è¿›åº¦æ¡ */}
        <div className="relative w-full h-1.5 bg-muted rounded-full overflow-hidden">
          <div
            className="absolute top-0 left-0 h-full bg-primary"
            style={{ 
              width: useMemo(() => {
                if (!duration || duration === 0) return '0%'
                const percentage = Math.min(100, Math.max(0, (currentTime / duration) * 100))
                return `${percentage}%`
              }, [currentTime, duration])
            }}
          />
        </div>

        {/* å¥å­æ˜¾ç¤ºåŒºåŸŸ */}
        <div className="mt-4 max-h-60 overflow-y-auto border rounded-md p-3">
          {processedTimestamps.length > 0 ? (
            processedTimestamps.map((sentence, index) => (
              <p
                key={index}
                className={`py-1 px-2 my-1 rounded cursor-pointer transition-colors ${
                  index === currentSentenceIndex
                    ? "bg-primary/20 font-medium border-l-4 border-primary"
                    : "hover:bg-muted"
                }`}
                onClick={() => jumpToSentence(index)}
                data-start-time={sentence.start}
                data-end-time={sentence.end}
              >
                {sentence.text}
              </p>
            ))
          ) : (
            <div className="flex justify-center py-4">
              <div className="animate-spin rounded-full h-6 w-6 border-t-2 border-b-2 border-primary"></div>
            </div>
          )}
        </div>
      </CardContent>
    </Card>
  )
}
